{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing,metrics\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5558, 50)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"df_perfect_final.csv\", header=0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['Unnamed: 0.1','Unnamed: 0','funding_velocity','normalized_name'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>success</th>\n",
       "      <th>investor_participants</th>\n",
       "      <th>Round_1_amount</th>\n",
       "      <th>Round_2_amount</th>\n",
       "      <th>Round_3_amount</th>\n",
       "      <th>Round_4_amount</th>\n",
       "      <th>Round_5_amount</th>\n",
       "      <th>Round_6_amount</th>\n",
       "      <th>funding_rounds</th>\n",
       "      <th>funding_total_usd</th>\n",
       "      <th>...</th>\n",
       "      <th>ecommerce</th>\n",
       "      <th>analytics</th>\n",
       "      <th>games_video</th>\n",
       "      <th>cleantech</th>\n",
       "      <th>other_category</th>\n",
       "      <th>Round1_Missing_fg</th>\n",
       "      <th>Round2_Missing_fg</th>\n",
       "      <th>Round3_Missing_fg</th>\n",
       "      <th>Round4_Missing_fg</th>\n",
       "      <th>Round5_Missing_fg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5558.000000</td>\n",
       "      <td>5558.000000</td>\n",
       "      <td>5.558000e+03</td>\n",
       "      <td>5.558000e+03</td>\n",
       "      <td>5.558000e+03</td>\n",
       "      <td>5.558000e+03</td>\n",
       "      <td>5.558000e+03</td>\n",
       "      <td>5.558000e+03</td>\n",
       "      <td>5558.000000</td>\n",
       "      <td>5.558000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>5558.000000</td>\n",
       "      <td>5558.000000</td>\n",
       "      <td>5558.000000</td>\n",
       "      <td>5558.000000</td>\n",
       "      <td>5558.000000</td>\n",
       "      <td>5558.000000</td>\n",
       "      <td>5558.000000</td>\n",
       "      <td>5558.000000</td>\n",
       "      <td>5558.000000</td>\n",
       "      <td>5558.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.285534</td>\n",
       "      <td>4.083483</td>\n",
       "      <td>4.650036e+05</td>\n",
       "      <td>2.202773e+06</td>\n",
       "      <td>2.995584e+06</td>\n",
       "      <td>2.385833e+06</td>\n",
       "      <td>2.111367e+06</td>\n",
       "      <td>6.664466e+05</td>\n",
       "      <td>2.229219</td>\n",
       "      <td>1.554532e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039223</td>\n",
       "      <td>0.037963</td>\n",
       "      <td>0.030946</td>\n",
       "      <td>0.031846</td>\n",
       "      <td>0.321698</td>\n",
       "      <td>0.462936</td>\n",
       "      <td>0.233357</td>\n",
       "      <td>0.185498</td>\n",
       "      <td>0.166607</td>\n",
       "      <td>0.146456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.451709</td>\n",
       "      <td>5.401918</td>\n",
       "      <td>1.404895e+06</td>\n",
       "      <td>6.170518e+06</td>\n",
       "      <td>8.517704e+06</td>\n",
       "      <td>9.383949e+06</td>\n",
       "      <td>1.331391e+07</td>\n",
       "      <td>5.121158e+06</td>\n",
       "      <td>1.519827</td>\n",
       "      <td>3.325432e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194142</td>\n",
       "      <td>0.191125</td>\n",
       "      <td>0.173188</td>\n",
       "      <td>0.175606</td>\n",
       "      <td>0.467170</td>\n",
       "      <td>0.498669</td>\n",
       "      <td>0.423006</td>\n",
       "      <td>0.388736</td>\n",
       "      <td>0.372658</td>\n",
       "      <td>0.353594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.700000e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000e+05</td>\n",
       "      <td>2.400000e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.520000e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>6.000000e+07</td>\n",
       "      <td>2.250000e+08</td>\n",
       "      <td>1.401297e+08</td>\n",
       "      <td>2.580000e+08</td>\n",
       "      <td>4.200000e+08</td>\n",
       "      <td>2.476409e+08</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>5.620000e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           success  investor_participants  Round_1_amount  Round_2_amount  \\\n",
       "count  5558.000000            5558.000000    5.558000e+03    5.558000e+03   \n",
       "mean      0.285534               4.083483    4.650036e+05    2.202773e+06   \n",
       "std       0.451709               5.401918    1.404895e+06    6.170518e+06   \n",
       "min       0.000000               0.000000    0.000000e+00    0.000000e+00   \n",
       "25%       0.000000               0.000000    0.000000e+00    0.000000e+00   \n",
       "50%       0.000000               2.000000    0.000000e+00    0.000000e+00   \n",
       "75%       1.000000               6.000000    5.000000e+05    2.400000e+06   \n",
       "max       1.000000              54.000000    6.000000e+07    2.250000e+08   \n",
       "\n",
       "       Round_3_amount  Round_4_amount  Round_5_amount  Round_6_amount  \\\n",
       "count    5.558000e+03    5.558000e+03    5.558000e+03    5.558000e+03   \n",
       "mean     2.995584e+06    2.385833e+06    2.111367e+06    6.664466e+05   \n",
       "std      8.517704e+06    9.383949e+06    1.331391e+07    5.121158e+06   \n",
       "min      0.000000e+00    0.000000e+00    0.000000e+00    0.000000e+00   \n",
       "25%      0.000000e+00    0.000000e+00    0.000000e+00    0.000000e+00   \n",
       "50%      0.000000e+00    0.000000e+00    0.000000e+00    0.000000e+00   \n",
       "75%      0.000000e+00    0.000000e+00    0.000000e+00    0.000000e+00   \n",
       "max      1.401297e+08    2.580000e+08    4.200000e+08    2.476409e+08   \n",
       "\n",
       "       funding_rounds  funding_total_usd  ...    ecommerce    analytics  \\\n",
       "count     5558.000000       5.558000e+03  ...  5558.000000  5558.000000   \n",
       "mean         2.229219       1.554532e+07  ...     0.039223     0.037963   \n",
       "std          1.519827       3.325432e+07  ...     0.194142     0.191125   \n",
       "min          1.000000       1.000000e+03  ...     0.000000     0.000000   \n",
       "25%          1.000000       8.000000e+05  ...     0.000000     0.000000   \n",
       "50%          2.000000       3.700000e+06  ...     0.000000     0.000000   \n",
       "75%          3.000000       1.520000e+07  ...     0.000000     0.000000   \n",
       "max         14.000000       5.620000e+08  ...     1.000000     1.000000   \n",
       "\n",
       "       games_video    cleantech  other_category  Round1_Missing_fg  \\\n",
       "count  5558.000000  5558.000000     5558.000000        5558.000000   \n",
       "mean      0.030946     0.031846        0.321698           0.462936   \n",
       "std       0.173188     0.175606        0.467170           0.498669   \n",
       "min       0.000000     0.000000        0.000000           0.000000   \n",
       "25%       0.000000     0.000000        0.000000           0.000000   \n",
       "50%       0.000000     0.000000        0.000000           0.000000   \n",
       "75%       0.000000     0.000000        1.000000           1.000000   \n",
       "max       1.000000     1.000000        1.000000           1.000000   \n",
       "\n",
       "       Round2_Missing_fg  Round3_Missing_fg  Round4_Missing_fg  \\\n",
       "count        5558.000000        5558.000000        5558.000000   \n",
       "mean            0.233357           0.185498           0.166607   \n",
       "std             0.423006           0.388736           0.372658   \n",
       "min             0.000000           0.000000           0.000000   \n",
       "25%             0.000000           0.000000           0.000000   \n",
       "50%             0.000000           0.000000           0.000000   \n",
       "75%             0.000000           0.000000           0.000000   \n",
       "max             1.000000           1.000000           1.000000   \n",
       "\n",
       "       Round5_Missing_fg  \n",
       "count        5558.000000  \n",
       "mean            0.146456  \n",
       "std             0.353594  \n",
       "min             0.000000  \n",
       "25%             0.000000  \n",
       "50%             0.000000  \n",
       "75%             0.000000  \n",
       "max             1.000000  \n",
       "\n",
       "[8 rows x 46 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#from sklearn import preprocessing\n",
    "minmaxScaler = preprocessing.MinMaxScaler() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "df1=minmaxScaler.fit_transform(df[['Round_1_amount','Round_2_amount','Round_3_amount','Round_4_amount','Round_5_amount','Round_6_amount',\\\n",
    "                              'funding_total_usd','days_since_last_funding']])\n",
    "df2=pd.DataFrame(df1,columns=['Round_1_amount','Round_2_amount','Round_3_amount','Round_4_amount','Round_5_amount','Round_6_amount',\\\n",
    "                              'funding_total_usd','days_since_last_funding'])\n",
    "df1=df.drop(['Round_1_amount','Round_2_amount','Round_3_amount','Round_4_amount','Round_5_amount','Round_6_amount',\\\n",
    "                              'funding_total_usd','days_since_last_funding'],axis=1)\n",
    "dff=pd.concat([df1,df2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>success</th>\n",
       "      <th>investor_participants</th>\n",
       "      <th>Round_1_amount</th>\n",
       "      <th>Round_2_amount</th>\n",
       "      <th>Round_3_amount</th>\n",
       "      <th>Round_4_amount</th>\n",
       "      <th>Round_5_amount</th>\n",
       "      <th>Round_6_amount</th>\n",
       "      <th>funding_rounds</th>\n",
       "      <th>funding_total_usd</th>\n",
       "      <th>...</th>\n",
       "      <th>ecommerce</th>\n",
       "      <th>analytics</th>\n",
       "      <th>games_video</th>\n",
       "      <th>cleantech</th>\n",
       "      <th>other_category</th>\n",
       "      <th>Round1_Missing_fg</th>\n",
       "      <th>Round2_Missing_fg</th>\n",
       "      <th>Round3_Missing_fg</th>\n",
       "      <th>Round4_Missing_fg</th>\n",
       "      <th>Round5_Missing_fg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5558.000000</td>\n",
       "      <td>5558.000000</td>\n",
       "      <td>5.558000e+03</td>\n",
       "      <td>5.558000e+03</td>\n",
       "      <td>5.558000e+03</td>\n",
       "      <td>5.558000e+03</td>\n",
       "      <td>5.558000e+03</td>\n",
       "      <td>5.558000e+03</td>\n",
       "      <td>5558.000000</td>\n",
       "      <td>5.558000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>5558.000000</td>\n",
       "      <td>5558.000000</td>\n",
       "      <td>5558.000000</td>\n",
       "      <td>5558.000000</td>\n",
       "      <td>5558.000000</td>\n",
       "      <td>5558.000000</td>\n",
       "      <td>5558.000000</td>\n",
       "      <td>5558.000000</td>\n",
       "      <td>5558.000000</td>\n",
       "      <td>5558.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.285534</td>\n",
       "      <td>4.083483</td>\n",
       "      <td>4.650036e+05</td>\n",
       "      <td>2.202773e+06</td>\n",
       "      <td>2.995584e+06</td>\n",
       "      <td>2.385833e+06</td>\n",
       "      <td>2.111367e+06</td>\n",
       "      <td>6.664466e+05</td>\n",
       "      <td>2.229219</td>\n",
       "      <td>1.554532e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039223</td>\n",
       "      <td>0.037963</td>\n",
       "      <td>0.030946</td>\n",
       "      <td>0.031846</td>\n",
       "      <td>0.321698</td>\n",
       "      <td>0.462936</td>\n",
       "      <td>0.233357</td>\n",
       "      <td>0.185498</td>\n",
       "      <td>0.166607</td>\n",
       "      <td>0.146456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.451709</td>\n",
       "      <td>5.401918</td>\n",
       "      <td>1.404895e+06</td>\n",
       "      <td>6.170518e+06</td>\n",
       "      <td>8.517704e+06</td>\n",
       "      <td>9.383949e+06</td>\n",
       "      <td>1.331391e+07</td>\n",
       "      <td>5.121158e+06</td>\n",
       "      <td>1.519827</td>\n",
       "      <td>3.325432e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194142</td>\n",
       "      <td>0.191125</td>\n",
       "      <td>0.173188</td>\n",
       "      <td>0.175606</td>\n",
       "      <td>0.467170</td>\n",
       "      <td>0.498669</td>\n",
       "      <td>0.423006</td>\n",
       "      <td>0.388736</td>\n",
       "      <td>0.372658</td>\n",
       "      <td>0.353594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.700000e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000e+05</td>\n",
       "      <td>2.400000e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.520000e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>6.000000e+07</td>\n",
       "      <td>2.250000e+08</td>\n",
       "      <td>1.401297e+08</td>\n",
       "      <td>2.580000e+08</td>\n",
       "      <td>4.200000e+08</td>\n",
       "      <td>2.476409e+08</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>5.620000e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           success  investor_participants  Round_1_amount  Round_2_amount  \\\n",
       "count  5558.000000            5558.000000    5.558000e+03    5.558000e+03   \n",
       "mean      0.285534               4.083483    4.650036e+05    2.202773e+06   \n",
       "std       0.451709               5.401918    1.404895e+06    6.170518e+06   \n",
       "min       0.000000               0.000000    0.000000e+00    0.000000e+00   \n",
       "25%       0.000000               0.000000    0.000000e+00    0.000000e+00   \n",
       "50%       0.000000               2.000000    0.000000e+00    0.000000e+00   \n",
       "75%       1.000000               6.000000    5.000000e+05    2.400000e+06   \n",
       "max       1.000000              54.000000    6.000000e+07    2.250000e+08   \n",
       "\n",
       "       Round_3_amount  Round_4_amount  Round_5_amount  Round_6_amount  \\\n",
       "count    5.558000e+03    5.558000e+03    5.558000e+03    5.558000e+03   \n",
       "mean     2.995584e+06    2.385833e+06    2.111367e+06    6.664466e+05   \n",
       "std      8.517704e+06    9.383949e+06    1.331391e+07    5.121158e+06   \n",
       "min      0.000000e+00    0.000000e+00    0.000000e+00    0.000000e+00   \n",
       "25%      0.000000e+00    0.000000e+00    0.000000e+00    0.000000e+00   \n",
       "50%      0.000000e+00    0.000000e+00    0.000000e+00    0.000000e+00   \n",
       "75%      0.000000e+00    0.000000e+00    0.000000e+00    0.000000e+00   \n",
       "max      1.401297e+08    2.580000e+08    4.200000e+08    2.476409e+08   \n",
       "\n",
       "       funding_rounds  funding_total_usd  ...    ecommerce    analytics  \\\n",
       "count     5558.000000       5.558000e+03  ...  5558.000000  5558.000000   \n",
       "mean         2.229219       1.554532e+07  ...     0.039223     0.037963   \n",
       "std          1.519827       3.325432e+07  ...     0.194142     0.191125   \n",
       "min          1.000000       1.000000e+03  ...     0.000000     0.000000   \n",
       "25%          1.000000       8.000000e+05  ...     0.000000     0.000000   \n",
       "50%          2.000000       3.700000e+06  ...     0.000000     0.000000   \n",
       "75%          3.000000       1.520000e+07  ...     0.000000     0.000000   \n",
       "max         14.000000       5.620000e+08  ...     1.000000     1.000000   \n",
       "\n",
       "       games_video    cleantech  other_category  Round1_Missing_fg  \\\n",
       "count  5558.000000  5558.000000     5558.000000        5558.000000   \n",
       "mean      0.030946     0.031846        0.321698           0.462936   \n",
       "std       0.173188     0.175606        0.467170           0.498669   \n",
       "min       0.000000     0.000000        0.000000           0.000000   \n",
       "25%       0.000000     0.000000        0.000000           0.000000   \n",
       "50%       0.000000     0.000000        0.000000           0.000000   \n",
       "75%       0.000000     0.000000        1.000000           1.000000   \n",
       "max       1.000000     1.000000        1.000000           1.000000   \n",
       "\n",
       "       Round2_Missing_fg  Round3_Missing_fg  Round4_Missing_fg  \\\n",
       "count        5558.000000        5558.000000        5558.000000   \n",
       "mean            0.233357           0.185498           0.166607   \n",
       "std             0.423006           0.388736           0.372658   \n",
       "min             0.000000           0.000000           0.000000   \n",
       "25%             0.000000           0.000000           0.000000   \n",
       "50%             0.000000           0.000000           0.000000   \n",
       "75%             0.000000           0.000000           0.000000   \n",
       "max             1.000000           1.000000           1.000000   \n",
       "\n",
       "       Round5_Missing_fg  \n",
       "count        5558.000000  \n",
       "mean            0.146456  \n",
       "std             0.353594  \n",
       "min             0.000000  \n",
       "25%             0.000000  \n",
       "50%             0.000000  \n",
       "75%             0.000000  \n",
       "max             1.000000  \n",
       "\n",
       "[8 rows x 46 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df.drop('success',axis=1), \n",
    "                                                    df['success'], test_size=0.30, \n",
    "                                                    random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3890, 45)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation,Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 64)                2944      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 12,449\n",
      "Trainable params: 12,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64,input_dim=45,activation='sigmoid'))\n",
    "# Drop\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(16,activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def precision(y_true, y_pred, average='None'):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred, average='micro'):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def f1(y_true, y_pred, average='weighted'):\n",
    "    def recall(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='RMSProp',metrics=['accuracy',f1])\n",
    "#sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3890/3890 [==============================] - 2s 526us/step - loss: 0.5711 - accuracy: 0.7118 - f1: 0.1203\n",
      "Epoch 2/100\n",
      "3890/3890 [==============================] - 0s 67us/step - loss: 0.5674 - accuracy: 0.7157 - f1: 0.1250\n",
      "Epoch 3/100\n",
      "3890/3890 [==============================] - 0s 66us/step - loss: 0.5710 - accuracy: 0.7208 - f1: 0.1709\n",
      "Epoch 4/100\n",
      "3890/3890 [==============================] - 0s 66us/step - loss: 0.5711 - accuracy: 0.7170 - f1: 0.1711\n",
      "Epoch 5/100\n",
      "3890/3890 [==============================] - 0s 69us/step - loss: 0.5700 - accuracy: 0.7190 - f1: 0.1609\n",
      "Epoch 6/100\n",
      "3890/3890 [==============================] - 0s 87us/step - loss: 0.5690 - accuracy: 0.7136 - f1: 0.1514\n",
      "Epoch 7/100\n",
      "3890/3890 [==============================] - 0s 68us/step - loss: 0.5701 - accuracy: 0.7180 - f1: 0.1721\n",
      "Epoch 8/100\n",
      "3890/3890 [==============================] - 0s 84us/step - loss: 0.5693 - accuracy: 0.7167 - f1: 0.1461\n",
      "Epoch 9/100\n",
      "3890/3890 [==============================] - 0s 68us/step - loss: 0.5706 - accuracy: 0.7177 - f1: 0.1578\n",
      "Epoch 10/100\n",
      "3890/3890 [==============================] - 0s 72us/step - loss: 0.5670 - accuracy: 0.7219 - f1: 0.2031\n",
      "Epoch 11/100\n",
      "3890/3890 [==============================] - 0s 79us/step - loss: 0.5720 - accuracy: 0.7208 - f1: 0.1746\n",
      "Epoch 12/100\n",
      "3890/3890 [==============================] - 0s 73us/step - loss: 0.5692 - accuracy: 0.7198 - f1: 0.1607\n",
      "Epoch 13/100\n",
      "3890/3890 [==============================] - 0s 70us/step - loss: 0.5695 - accuracy: 0.7139 - f1: 0.1552\n",
      "Epoch 14/100\n",
      "3890/3890 [==============================] - 0s 71us/step - loss: 0.5702 - accuracy: 0.7159 - f1: 0.1762\n",
      "Epoch 15/100\n",
      "3890/3890 [==============================] - 0s 66us/step - loss: 0.5693 - accuracy: 0.7147 - f1: 0.1355\n",
      "Epoch 16/100\n",
      "3890/3890 [==============================] - 0s 67us/step - loss: 0.5679 - accuracy: 0.7183 - f1: 0.1359\n",
      "Epoch 17/100\n",
      "3890/3890 [==============================] - 0s 68us/step - loss: 0.5704 - accuracy: 0.7139 - f1: 0.1474\n",
      "Epoch 18/100\n",
      "3890/3890 [==============================] - 0s 69us/step - loss: 0.5688 - accuracy: 0.7154 - f1: 0.1301\n",
      "Epoch 19/100\n",
      "3890/3890 [==============================] - 0s 94us/step - loss: 0.5682 - accuracy: 0.7170 - f1: 0.1565\n",
      "Epoch 20/100\n",
      "3890/3890 [==============================] - 0s 83us/step - loss: 0.5660 - accuracy: 0.7177 - f1: 0.1429\n",
      "Epoch 21/100\n",
      "3890/3890 [==============================] - 0s 84us/step - loss: 0.5662 - accuracy: 0.7208 - f1: 0.1584\n",
      "Epoch 22/100\n",
      "3890/3890 [==============================] - 0s 70us/step - loss: 0.5682 - accuracy: 0.7165 - f1: 0.1694\n",
      "Epoch 23/100\n",
      "3890/3890 [==============================] - 0s 72us/step - loss: 0.5684 - accuracy: 0.7206 - f1: 0.1667\n",
      "Epoch 24/100\n",
      "3890/3890 [==============================] - 0s 69us/step - loss: 0.5674 - accuracy: 0.7154 - f1: 0.1458\n",
      "Epoch 25/100\n",
      "3890/3890 [==============================] - 0s 68us/step - loss: 0.5668 - accuracy: 0.7167 - f1: 0.1648\n",
      "Epoch 26/100\n",
      "3890/3890 [==============================] - 0s 68us/step - loss: 0.5716 - accuracy: 0.7136 - f1: 0.1378\n",
      "Epoch 27/100\n",
      "3890/3890 [==============================] - 0s 88us/step - loss: 0.5709 - accuracy: 0.7126 - f1: 0.1103\n",
      "Epoch 28/100\n",
      "3890/3890 [==============================] - 0s 86us/step - loss: 0.5710 - accuracy: 0.7123 - f1: 0.1137\n",
      "Epoch 29/100\n",
      "3890/3890 [==============================] - 0s 85us/step - loss: 0.5690 - accuracy: 0.7180 - f1: 0.1261\n",
      "Epoch 30/100\n",
      "3890/3890 [==============================] - 0s 87us/step - loss: 0.5692 - accuracy: 0.7183 - f1: 0.1615\n",
      "Epoch 31/100\n",
      "3890/3890 [==============================] - 0s 79us/step - loss: 0.5705 - accuracy: 0.7190 - f1: 0.1558\n",
      "Epoch 32/100\n",
      "3890/3890 [==============================] - 0s 86us/step - loss: 0.5707 - accuracy: 0.7103 - f1: 0.1299\n",
      "Epoch 33/100\n",
      "3890/3890 [==============================] - 0s 96us/step - loss: 0.5690 - accuracy: 0.7129 - f1: 0.1326\n",
      "Epoch 34/100\n",
      "3890/3890 [==============================] - 0s 68us/step - loss: 0.5689 - accuracy: 0.7136 - f1: 0.1423\n",
      "Epoch 35/100\n",
      "3890/3890 [==============================] - 0s 75us/step - loss: 0.5683 - accuracy: 0.7175 - f1: 0.1384\n",
      "Epoch 36/100\n",
      "3890/3890 [==============================] - 0s 69us/step - loss: 0.5657 - accuracy: 0.7183 - f1: 0.1681\n",
      "Epoch 37/100\n",
      "3890/3890 [==============================] - 0s 69us/step - loss: 0.5694 - accuracy: 0.7149 - f1: 0.1513\n",
      "Epoch 38/100\n",
      "3890/3890 [==============================] - 0s 88us/step - loss: 0.5721 - accuracy: 0.7190 - f1: 0.1825\n",
      "Epoch 39/100\n",
      "3890/3890 [==============================] - 0s 80us/step - loss: 0.5698 - accuracy: 0.7134 - f1: 0.1375\n",
      "Epoch 40/100\n",
      "3890/3890 [==============================] - 0s 71us/step - loss: 0.5694 - accuracy: 0.7177 - f1: 0.1266\n",
      "Epoch 41/100\n",
      "3890/3890 [==============================] - 0s 83us/step - loss: 0.5684 - accuracy: 0.7159 - f1: 0.1380\n",
      "Epoch 42/100\n",
      "3890/3890 [==============================] - 0s 120us/step - loss: 0.5656 - accuracy: 0.7185 - f1: 0.1984\n",
      "Epoch 43/100\n",
      "3890/3890 [==============================] - 0s 84us/step - loss: 0.5690 - accuracy: 0.7152 - f1: 0.1528\n",
      "Epoch 44/100\n",
      "3890/3890 [==============================] - 0s 105us/step - loss: 0.5691 - accuracy: 0.7203 - f1: 0.1884\n",
      "Epoch 45/100\n",
      "3890/3890 [==============================] - 0s 69us/step - loss: 0.5663 - accuracy: 0.7195 - f1: 0.1644\n",
      "Epoch 46/100\n",
      "3890/3890 [==============================] - 0s 74us/step - loss: 0.5673 - accuracy: 0.7154 - f1: 0.1410\n",
      "Epoch 47/100\n",
      "3890/3890 [==============================] - 0s 73us/step - loss: 0.5699 - accuracy: 0.7139 - f1: 0.1459\n",
      "Epoch 48/100\n",
      "3890/3890 [==============================] - 0s 70us/step - loss: 0.5685 - accuracy: 0.7183 - f1: 0.1433\n",
      "Epoch 49/100\n",
      "3890/3890 [==============================] - 0s 71us/step - loss: 0.5668 - accuracy: 0.7165 - f1: 0.1325\n",
      "Epoch 50/100\n",
      "3890/3890 [==============================] - 0s 76us/step - loss: 0.5694 - accuracy: 0.7195 - f1: 0.1468\n",
      "Epoch 51/100\n",
      "3890/3890 [==============================] - 0s 71us/step - loss: 0.5682 - accuracy: 0.7180 - f1: 0.1515\n",
      "Epoch 52/100\n",
      "3890/3890 [==============================] - 0s 71us/step - loss: 0.5686 - accuracy: 0.7185 - f1: 0.1135\n",
      "Epoch 53/100\n",
      "3890/3890 [==============================] - 0s 71us/step - loss: 0.5674 - accuracy: 0.7152 - f1: 0.1403\n",
      "Epoch 54/100\n",
      "3890/3890 [==============================] - 0s 92us/step - loss: 0.5683 - accuracy: 0.7172 - f1: 0.1393\n",
      "Epoch 55/100\n",
      "3890/3890 [==============================] - 0s 74us/step - loss: 0.5666 - accuracy: 0.7154 - f1: 0.1403\n",
      "Epoch 56/100\n",
      "3890/3890 [==============================] - 0s 75us/step - loss: 0.5677 - accuracy: 0.7175 - f1: 0.1376\n",
      "Epoch 57/100\n",
      "3890/3890 [==============================] - 0s 77us/step - loss: 0.5678 - accuracy: 0.7162 - f1: 0.1607\n",
      "Epoch 58/100\n",
      "3890/3890 [==============================] - 0s 69us/step - loss: 0.5662 - accuracy: 0.7198 - f1: 0.1729\n",
      "Epoch 59/100\n",
      "3890/3890 [==============================] - 0s 68us/step - loss: 0.5681 - accuracy: 0.7154 - f1: 0.1648\n",
      "Epoch 60/100\n",
      "3890/3890 [==============================] - 0s 67us/step - loss: 0.5678 - accuracy: 0.7141 - f1: 0.1528\n",
      "Epoch 61/100\n",
      "3890/3890 [==============================] - 0s 73us/step - loss: 0.5681 - accuracy: 0.7221 - f1: 0.1576\n",
      "Epoch 62/100\n",
      "3890/3890 [==============================] - 0s 76us/step - loss: 0.5693 - accuracy: 0.7198 - f1: 0.1672\n",
      "Epoch 63/100\n",
      "3890/3890 [==============================] - 0s 69us/step - loss: 0.5680 - accuracy: 0.7139 - f1: 0.1441\n",
      "Epoch 64/100\n",
      "3890/3890 [==============================] - 0s 72us/step - loss: 0.5708 - accuracy: 0.7162 - f1: 0.1510\n",
      "Epoch 65/100\n",
      "3890/3890 [==============================] - 0s 75us/step - loss: 0.5696 - accuracy: 0.7141 - f1: 0.1541\n",
      "Epoch 66/100\n",
      "3890/3890 [==============================] - 0s 70us/step - loss: 0.5667 - accuracy: 0.7162 - f1: 0.1560\n",
      "Epoch 67/100\n",
      "3890/3890 [==============================] - 0s 68us/step - loss: 0.5694 - accuracy: 0.7190 - f1: 0.1364\n",
      "Epoch 68/100\n",
      "3890/3890 [==============================] - 0s 69us/step - loss: 0.5665 - accuracy: 0.7213 - f1: 0.1703\n",
      "Epoch 69/100\n",
      "3890/3890 [==============================] - 0s 75us/step - loss: 0.5675 - accuracy: 0.7167 - f1: 0.1471\n",
      "Epoch 70/100\n",
      "3890/3890 [==============================] - 0s 68us/step - loss: 0.5657 - accuracy: 0.7183 - f1: 0.1868\n",
      "Epoch 71/100\n",
      "3890/3890 [==============================] - 0s 69us/step - loss: 0.5676 - accuracy: 0.7195 - f1: 0.2135\n",
      "Epoch 72/100\n",
      "3890/3890 [==============================] - 0s 70us/step - loss: 0.5676 - accuracy: 0.7208 - f1: 0.1861\n",
      "Epoch 73/100\n",
      "3890/3890 [==============================] - 0s 73us/step - loss: 0.5691 - accuracy: 0.7229 - f1: 0.2106\n",
      "Epoch 74/100\n",
      "3890/3890 [==============================] - 0s 68us/step - loss: 0.5711 - accuracy: 0.7144 - f1: 0.1546\n",
      "Epoch 75/100\n",
      "3890/3890 [==============================] - 0s 67us/step - loss: 0.5674 - accuracy: 0.7219 - f1: 0.1917\n",
      "Epoch 76/100\n",
      "3890/3890 [==============================] - 0s 69us/step - loss: 0.5653 - accuracy: 0.7162 - f1: 0.1873\n",
      "Epoch 77/100\n",
      "3890/3890 [==============================] - 0s 69us/step - loss: 0.5670 - accuracy: 0.7165 - f1: 0.1937\n",
      "Epoch 78/100\n",
      "3890/3890 [==============================] - 0s 70us/step - loss: 0.5691 - accuracy: 0.7131 - f1: 0.1386\n",
      "Epoch 79/100\n",
      "3890/3890 [==============================] - 0s 73us/step - loss: 0.5708 - accuracy: 0.7144 - f1: 0.1207\n",
      "Epoch 80/100\n",
      "3890/3890 [==============================] - 0s 69us/step - loss: 0.5689 - accuracy: 0.7193 - f1: 0.1632\n",
      "Epoch 81/100\n",
      "3890/3890 [==============================] - 0s 68us/step - loss: 0.5689 - accuracy: 0.7157 - f1: 0.1246\n",
      "Epoch 82/100\n",
      "3890/3890 [==============================] - 0s 70us/step - loss: 0.5649 - accuracy: 0.7206 - f1: 0.1682\n",
      "Epoch 83/100\n",
      "3890/3890 [==============================] - 0s 102us/step - loss: 0.5690 - accuracy: 0.7170 - f1: 0.1500\n",
      "Epoch 84/100\n",
      "3890/3890 [==============================] - 0s 88us/step - loss: 0.5677 - accuracy: 0.7167 - f1: 0.1846\n",
      "Epoch 85/100\n",
      "3890/3890 [==============================] - 0s 86us/step - loss: 0.5719 - accuracy: 0.7165 - f1: 0.1584\n",
      "Epoch 86/100\n",
      "3890/3890 [==============================] - 0s 85us/step - loss: 0.5653 - accuracy: 0.7221 - f1: 0.1764\n",
      "Epoch 87/100\n",
      "3890/3890 [==============================] - 0s 81us/step - loss: 0.5670 - accuracy: 0.7185 - f1: 0.1607\n",
      "Epoch 88/100\n",
      "3890/3890 [==============================] - 0s 83us/step - loss: 0.5674 - accuracy: 0.7206 - f1: 0.1766\n",
      "Epoch 89/100\n",
      "3890/3890 [==============================] - 0s 77us/step - loss: 0.5690 - accuracy: 0.7195 - f1: 0.1792\n",
      "Epoch 90/100\n",
      "3890/3890 [==============================] - 0s 75us/step - loss: 0.5686 - accuracy: 0.7159 - f1: 0.1513\n",
      "Epoch 91/100\n",
      "3890/3890 [==============================] - 0s 70us/step - loss: 0.5676 - accuracy: 0.7167 - f1: 0.1789\n",
      "Epoch 92/100\n",
      "3890/3890 [==============================] - 0s 69us/step - loss: 0.5669 - accuracy: 0.7201 - f1: 0.1791\n",
      "Epoch 93/100\n",
      "3890/3890 [==============================] - 0s 68us/step - loss: 0.5678 - accuracy: 0.7177 - f1: 0.2041\n",
      "Epoch 94/100\n",
      "3890/3890 [==============================] - 0s 72us/step - loss: 0.5667 - accuracy: 0.7159 - f1: 0.1789\n",
      "Epoch 95/100\n",
      "3890/3890 [==============================] - 0s 68us/step - loss: 0.5701 - accuracy: 0.7193 - f1: 0.1841\n",
      "Epoch 96/100\n",
      "3890/3890 [==============================] - 0s 70us/step - loss: 0.5648 - accuracy: 0.7190 - f1: 0.1641\n",
      "Epoch 97/100\n",
      "3890/3890 [==============================] - 0s 76us/step - loss: 0.5674 - accuracy: 0.7170 - f1: 0.1679\n",
      "Epoch 98/100\n",
      "3890/3890 [==============================] - 0s 75us/step - loss: 0.5710 - accuracy: 0.7147 - f1: 0.1851\n",
      "Epoch 99/100\n",
      "3890/3890 [==============================] - 0s 70us/step - loss: 0.5701 - accuracy: 0.7126 - f1: 0.1280\n",
      "Epoch 100/100\n",
      "3890/3890 [==============================] - 0s 73us/step - loss: 0.5675 - accuracy: 0.7172 - f1: 0.1412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x14819b650>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train.values,y_train.values,epochs=100,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "        40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
       "        53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
       "        66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
       "        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "        92,  93,  94,  95,  96,  97,  98,  99, 100])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(start=1, stop=101, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,auc,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84      1200\n",
      "           1       0.00      0.00      0.00       468\n",
      "\n",
      "    accuracy                           0.72      1668\n",
      "   macro avg       0.36      0.50      0.42      1668\n",
      "weighted avg       0.52      0.72      0.60      1668\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.where(model.predict(x_test.values)>0.5,1,0)\n",
    "Cmatrix=confusion_matrix(y_test,y_pred)\n",
    "Creport=classification_report(y_test,y_pred)\n",
    "print(Creport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.602028837181301"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test,y_pred,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
